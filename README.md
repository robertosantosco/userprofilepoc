# User Profile POC

> **Uma Proof of Concept para centraliza√ß√£o e processamento de dados de perfil de usu√°rio em tempo real com arquitetura event-driven.**

## üìã Table of Contents

- [üéØ Vis√£o Geral & Problema (Contexto e motiva√ß√£o)](#-vis√£o-geral--problema)
- [üõ†Ô∏è Stack Tecnol√≥gica (Com quais ferramentas foi feito)](#Ô∏è-stack-tecnol√≥gica)
- [üèóÔ∏è Arquitetura & Design (Vis√£o macro do sistema)](#Ô∏è-arquitetura--design)
- [üìÅ Arquitetura de C√≥digo (Implementa√ß√£o pratica)](#-arquitetura-de-c√≥digo)
- [üíæ Write Repositories (Como os dados entram)](#-write-repositories)
- [üìñ Read Repositories (Como os dados saem)](#-read-repositories)
- [‚öôÔ∏è Workers (Como os dados sao processados)](#Ô∏è-workers)
- [üåê API Endpoints (Intefaces do sistema)](#-api-endpoints)
- [üöÄ Setup & Opera√ß√£o (Como usar)](#-setup--opera√ß√£o)
- [üìä Testes de Carga (Como testar)](#-testes-de-carga)


## üéØ Vis√£o Geral & Problema

### **Desafio**
Organiza√ß√µes modernas enfrentam o desafio de **dados de usu√°rio fragmentados** espalhados por m√∫ltiplos sistemas:
- Dados pontuais (perfil, prefer√™ncias, configura√ß√µes)
- Dados temporais (m√©tricas, KPIs, analytics)
- Relacionamentos complexos entre entidades
- Necessidade de consultas em tempo real com baixa lat√™ncia

### **Solu√ß√£o**
Uma **API User Profile centralizada** que:
- üéØ **Centraliza** dados de perfil em um modelo de grafo flex√≠vel
- ‚ö° **Processa** eventos em tempo real via Kafka
- üîÑ **Publica** domain events via CDC (Change Data Capture)
- üìä **Otimiza** consultas com cache Redis e read replicas
- üèóÔ∏è **Escala** horizontalmente com arquitetura event-driven

### **Benef√≠cios**
- **Performance**: Cache Redis + Read Replicas PostgreSQL
- **Escalabilidade**: Processamento ass√≠ncrono via Kafka
- **Flexibilidade**: Modelo de dados JSON + grafo din√¢mico
- **Observabilidade**: Domain events para auditoria e analytics
- **Consist√™ncia**: CDC garante sincroniza√ß√£o autom√°tica


## üõ†Ô∏è Stack Tecnol√≥gica

### **Backend & Runtime**
- **Go 1.24.4**: Performance + concorr√™ncia nativa
- **Gin Framework**: HTTP router r√°pido e minimalista
- **pgx/v5**: Driver PostgreSQL otimizado para Go
- **go-redis/v9**: Cliente Redis com cluster support

### **Storage & Cache**
- **PostgreSQL 16**: Banco relacional com suporte a JSON
- **Redis 7**: Cache distribu√≠do em cluster
- **Replica√ß√£o**: 1 primary + 2 read replicas para escalabilidade

### **Stream Processing & Integration**
- **Apache Flink**: Stream processing para normaliza√ß√£o de dados
- **Flink SQL**: Transforma√ß√µes declarativas de eventos

### **Messaging & Events**
- **Apache Kafka**: Message broker distribu√≠do
- **Debezium**: CDC platform para PostgreSQL
- **Kafka Connect**: Conectores para integra√ß√£o

### **Infrastructure**
- **Docker Compose**: Orquestra√ß√£o local
- **Make**: Automa√ß√£o de comandos
- **K6**: Testes de carga e performance

### **Justificativas T√©cnicas**

| Tecnologia | Por que escolhemos |
|------------|-------------------|
| **Apache Flink** | Stream processing nativo, SQL declarativo, conectores robustos |
| **Go** | Performance superior, concorr√™ncia nativa, binary √∫nico |
| **PostgreSQL** | ACID compliance, JSON nativo, replica√ß√£o robusta |
| **Redis** | Cache sub-milissegundo, estruturas de dados avan√ßadas |
| **Kafka** | Throughput alto, durabilidade, processamento de streams |
| **Debezium** | CDC sem impacto na aplica√ß√£o, garantia de entrega |

### **Benef√≠cios da Integra√ß√£o via Flink**

| Benef√≠cio | Descri√ß√£o |
|-----------|-----------|
| **Padroniza√ß√£o** | Unifica schemas heterog√™neos em contratos consistentes |
| **Escalabilidade** | Processa milh√µes de eventos por segundo |
| **Flexibilidade** | SQL declarativo para transforma√ß√µes complexas |
| **Toler√¢ncia a Falhas** | Checkpointing e recovery autom√°tico |
| **Baixa Lat√™ncia** | Stream processing com lat√™ncia sub-segundo |
| **Evolu√ß√£o de Schema** | Permite mudan√ßas nos sistemas upstream sem impacto |




## üèóÔ∏è Arquitetura & Design

### **Vis√£o Geral da Arquitetura**

```mermaid
%%{init: {"theme":"default","themeVariables":{"background":"#ffffff"}}}%%
flowchart LR

    subgraph STONE["üè¢ Stone Domain Services"]
        direction TB
        PAY[üí≥ Payment Service<br/><small>Transactions & settlements</small>]
        ACC[üè¶ Account Service<br/><small>Account lifecycle</small>]
        CRM[üë• CRM Service<br/><small>Customer interactions</small>]
        CDP[üìä CDP Platform<br/><small>Analytics & insights</small>]
        OTHER[‚öôÔ∏è Other Services<br/><small>Additional domains</small>]
    end

    subgraph KAFKA_ECOSYSTEM["üì° Event Streaming Platform"]
        direction TB
        
        subgraph INPUT_TOPICS["Input Events"]
            PAY_T[[payment.events<br/>]]
            ACC_T[[account.events<br/>]]
            CRM_T[[crm.events<br/>]]
            CDP_T[[cdp.events<br/>]]
            AGG_T[[aggregated.metrics<br/>]]
        end

        subgraph FLINK_PROCESSING["üåä Real-time Processing With Flink"]
            direction TB
            FLINK_NODE[Apache Flink Engine<br/><small>Multi-stage pipeline</small>]
            ENRICH[Data Enrichment]
            TRANSFORM[Schema Normalization]
            AGGREGATE[Entity Consolidation]
        end

        subgraph TOPICS["üì§ Processed Streams"]
            direction TB
            K1[[entities-edges<br/><small>Graph relationships</small>]]
            K2[[entity-properties<br/><small>Aggregated attributes</small>]]
            K3[[temporal-data<br/><small>Time-series metrics</small>]]
        end

        subgraph CDC_EVENTS["Change Data Capture"]
            DZ((üîÑ Debezium CDC<br/><small>Real-time DB changes</small>))
        end
        
        subgraph OUTPUT_TOPICS["Domain Events"]
            K_OUT[[user-profile.domain-events.v1<br/><small>Notify downstream services</small>]]
        end
    end


    subgraph PROCESSING["üîÑ Event Consumers"]
        direction TB
        C1[entities-edges-consumer<br/>üìä Graph processor<br/>]
        C2[entity-properties-consumer<br/>üè∑Ô∏è Property aggregator<br/><small>Dedup by entity</small>]
        C3[temporal-data-consumer<br/>‚è∞ Time-series handler<br/>]
        C4[cdc-transformer<br/>üîÑ Domain event publisher<br/><small>CDC to events</small>]
    end

    subgraph STORAGE["üíæ Storage Infrastructure"]
        direction TB
        
        subgraph PG_CLUSTER["PostgreSQL Cluster"]
            PG_W[(üîµ Primary<br/>Write operations<br/>)]
            PG_R1[(üü¢ Replica 1<br/>Read operations)]
            PG_R2[(üü¢ Replica 2<br/>Read operations)]
        end
        
        subgraph CACHE_LAYER["Cache Layer"]
            REDIS[(üî¥ Redis Cluster<br/>3 nodes<br/><small>LRU Strategy</small>)]
        end
    end

    subgraph API["üöÄ User Profile API"]
        direction TB
        GET_GRAPH[üìñ GET /graph<br/><small>Read user graph</small>]
        SYNC_ENTITIES[‚úèÔ∏è POST /sync/graph<br/><small>Update entities & edges</small>]
        SYNC_TEMPORAL[‚úèÔ∏è POST /sync/temporal<br/><small>Update temporal data</small>]
    end


    PAY -->|publishes| PAY_T
    ACC -->|publishes| ACC_T
    CRM -->|publishes| CRM_T
    CDP -->|publishes| CDP_T
    OTHER -->|publishes| AGG_T

    PAY_T & ACC_T & CRM_T & CDP_T & AGG_T -->|streams| FLINK_NODE
    
    FLINK_NODE --> ENRICH
    ENRICH --> TRANSFORM
    TRANSFORM --> AGGREGATE

    AGGREGATE -->|entities & relations| K1
    AGGREGATE -->|properties| K2
    AGGREGATE -->|temporal metrics| K3

    K1 -->|consumes| C1
    K2 -->|consumes| C2
    K3 -->|consumes| C3

    C1 & C2 & C3 -->|writes| PG_W

    PG_W -.->|replicates| PG_R1 & PG_R2
    PG_W -->|CDC events| DZ

    DZ -->|transforms| C4
    C4 -->|publishes| K_OUT

    GET_GRAPH --->|read/write| REDIS
    GET_GRAPH -->|fallback| PG_R1 & PG_R2

    SYNC_ENTITIES & SYNC_TEMPORAL -->|writes| PG_W
    SYNC_ENTITIES & SYNC_TEMPORAL -->|invalidates| REDIS



    style STONE fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    style KAFKA_ECOSYSTEM fill:#fff8e1,stroke:#f57c00,stroke-width:2px
    style FLINK_PROCESSING fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style TOPICS fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style PROCESSING fill:#ede7f6,stroke:#4527a0,stroke-width:2px
    style STORAGE fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    style API fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    style INPUT_TOPICS fill:#fff3e0,stroke:#f57c00,stroke-width:1px
    style CDC_EVENTS fill:#fff8e1,stroke:#fbc02d,stroke-width:1px
    style OUTPUT_TOPICS fill:#fff3e0,stroke:#f57c00,stroke-width:1px
    style PG_CLUSTER fill:#ffebee,stroke:#c62828,stroke-width:1px
    style CACHE_LAYER fill:#fff3e0,stroke:#d84315,stroke-width:1px
```

### **Componentes Principais**

| Camada | Componente | Responsabilidade | Tecnologia |
|--------|------------|------------------|------------|
| **Integration** | **Apache Flink** | Stream processing e normaliza√ß√£o de dados | Apache Flink |
| **Application** | **User Profile API** | Interface HTTP para consultas | Go + Gin |
| **Storage** | **PostgreSQL Cluster** | Armazenamento principal (1 primary + 2 replicas) | PostgreSQL 16 |
| **Cache** | **Redis Cluster** | Cache distribu√≠do para consultas | Redis 7 |
| **Messaging** | **Kafka** | Message broker para eventos | Apache Kafka |
| **CDC** | **Debezium CDC** | Change Data Capture | Debezium + Kafka Connect |
| **Processing** | **Consumers** | Processamento ass√≠ncrono de eventos | Go workers |

### **Camada de Integra√ß√£o - Apache Flink**

A arquitetura utiliza **Apache Flink** como camada de integra√ß√£o para resolver o desafio de **m√∫ltiplos formatos de dados** de diferentes dom√≠nios:

#### **Desafio:**
- Centenas de microservi√ßos com eventos em formatos diferentes
- Payloads heterog√™neos (JSON schemas variados)
- Necessidade de evitar milhares de conectores espec√≠ficos
- Dados vindos de CDP, agrega√ß√µes e outras fontes externas

#### **Transforma√ß√µes T√≠picas:**

**Origem X ‚Üí User Profile Entities e Edges**
```sql
CREATE TABLE `flink.agg.user-profile.entities` (
  id                      STRING NOT NULL,
  reference               STRING NOT NULL,
  `type`                  STRING NOT NULL,
  edges                   ARRAY<STRING> NOT NULL,
  
  PRIMARY KEY (id) NOT NULL
) 
AS
SELECT
```

**Origem Y ‚Üí User Profile Properties**
```sql
CREATE TABLE `flink.agg.user-profile.entities.properties` (
  entity_id STRING NOT NULL,
  type      STRING NOT NULL,
  value     STRING NOT NULL,
  
  PRIMARY KEY (entity_id, type) NOT NULL
)
AS
SELECT
```

**Origem Z ‚Üí Temporal Data:**
```sql
CREATE TABLE `flink.agg.user-profile.entities.temporal-properties` (
  entity_id        STRING NOT NULL,
  type             STRING NOT NULL,
  value            STRING NOT NULL,
  period_reference TIMESTAMP NOT NULL,
  granularity      STRING NOT NULL,
  ts               TIMESTAMP_TZ(3) NOT NULL
  
  PRIMARY KEY (entity_id, type, period_reference) NOT NULL
)
```

### **Padr√µes Arquiteturais**

- **Repository Pattern**: Abstra√ß√£o de acesso a dados
- **CDC (Change Data Capture)**: Captura autom√°tica de mudan√ßas
- **Event Sourcing**: Rastreamento de todas as mudan√ßas
- **CQRS**: Separa√ß√£o de leitura (replicas + cache) e escrita
- **Domain Events**: Eventos de neg√≥cio para integra√ß√£o

### **Modelo de Dados**

```mermaid
erDiagram
    ENTITIES {
        bigint id PK
        text type
        text reference UK
        jsonb properties
        timestamp created_at
        timestamp updated_at
    }

    EDGES {
        bigint id PK
        bigint left_entity_id FK
        bigint right_entity_id FK
        text relationship_type
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }

    TEMPORAL_PROPERTIES {
        bigint id PK
        bigint entity_id FK
        text key
        jsonb value
        text granularity
        timestamp reference_date
        text idempotency_key UK
        timestamp created_at
        timestamp updated_at
    }

    ENTITIES ||--o{ EDGES : "left_entity"
    ENTITIES ||--o{ EDGES : "right_entity"
    ENTITIES ||--o{ TEMPORAL_PROPERTIES : "has"
```

## üìÅ Arquitetura de C√≥digo

### **Estrutura de Pastas**

```
src/
‚îú‚îÄ‚îÄ adapters/           # Camada de adaptadores
‚îÇ   ‚îú‚îÄ‚îÄ http/          # HTTP handlers e DTOs
‚îÇ   ‚îî‚îÄ‚îÄ kafka/         # Kafka consumers
‚îú‚îÄ‚îÄ cmd/               # Entry points da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ server/        # HTTP API server
‚îÇ   ‚îú‚îÄ‚îÄ cdc-transformer/ # CDC consumer
‚îÇ   ‚îî‚îÄ‚îÄ *-consumer/    # Kafka consumers
‚îú‚îÄ‚îÄ domain/            # Camada de dom√≠nio
‚îÇ   ‚îú‚îÄ‚îÄ entities/      # Entidades de neg√≥cio
‚îÇ   ‚îî‚îÄ‚îÄ value_objects.go # VOs e eventos
‚îú‚îÄ‚îÄ infra/             # Camada de infraestrutura
‚îÇ   ‚îú‚îÄ‚îÄ postgres/      # Cliente PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ redis/         # Cliente Redis
‚îÇ   ‚îú‚îÄ‚îÄ kafka/         # Cliente Kafka
‚îÇ   ‚îî‚îÄ‚îÄ debezium/      # Cliente Debezium CDC
‚îú‚îÄ‚îÄ repositories/      # Reposit√≥rios de dados
‚îú‚îÄ‚îÄ services/          # Servi√ßos de dom√≠nio
‚îÇ   ‚îî‚îÄ‚îÄ events/        # Event handlers
‚îî‚îÄ‚îÄ helper/            # Utilit√°rios
```

### **Camadas Arquiteturais**

```mermaid
graph TB
    subgraph "Presentation Layer"
        HTTP[HTTP Handlers]
        KAFKA[Kafka Consumers]
    end

    subgraph "Application Layer"
        SERVICES[Domain Services]
        EVENTS[Event Services]
    end

    subgraph "Domain Layer"
        ENTITIES[Domain Entities]
        VOS[Value Objects]
        DOMAIN_EVENTS[Domain Events]
    end

    subgraph "Infrastructure Layer"
        REPOS[Repositories]
        PG_CLIENT[PostgreSQL Client]
        REDIS_CLIENT[Redis Client]
        KAFKA_CLIENT[Kafka Client]
    end

    HTTP --> SERVICES
    KAFKA --> SERVICES
    SERVICES --> ENTITIES
    SERVICES --> REPOS
    EVENTS --> DOMAIN_EVENTS
    REPOS --> PG_CLIENT
    REPOS --> REDIS_CLIENT
    SERVICES --> EVENTS
```

### **Dependency Injection (Uber FX)**

```go
func main() {
    app := fx.New(
        // Infrastructure providers
        fx.Provide(
            newLogger,
            newPostgreSQLClient,
            newRedisClient,
            newKafkaClient,
        ),

        // Repository providers
        fx.Provide(
            newGraphQueryRepository,
            newCachedGraphRepository,
            newGraphWriteRepository,
        ),

        // Service providers
        fx.Provide(
            newGraphService,
            newTemporalDataService,
        ),

        // Server provider
        fx.Provide(newHTTPServer),

        // Lifecycle hooks
        fx.Invoke(registerServerHooks),
    )

    app.Run()
}
```

## üíæ Write Repositories

### **1. Estrat√©gia de Escrita**

A estrat√©gia de escrita dos reposit√≥rios √© baseada em **tr√™s pilares fundamentais** que garantem alta performance e consist√™ncia:

#### **Tabela Tempor√°ria em Mem√≥ria (Staging Area)**
Em cada transa√ß√£o, criamos uma **tabela tempor√°ria** que serve como √°rea de staging para todos os dados que precisamos inserir ou atualizar em diferentes tabelas:

```go
// Tabela tempor√°ria unificada para processar entidades e relacionamentos
tempTableQuery := `CREATE TEMP TABLE temp_sync_data (
    entity_type TEXT, entity_reference TEXT, entity_properties JSONB,
    source_reference TEXT, target_reference TEXT, relationship_type TEXT
) ON COMMIT DROP;`
```

Esta abordagem permite:
- **Unifica√ß√£o de dados**: Uma √∫nica estrutura para entities + relationships
- **Atomic processing**: Todos os dados ficam na mesma transa√ß√£o
- **Memory efficiency**: Tabela tempor√°ria existe apenas na RAM

#### **COPY FROM para Transfer Perform√°tico**
Utilizamos `COPY FROM` para transferir os dados de forma otimizada para o PostgreSQL:

```go
// Bulk transfer via COPY FROM (stream de dados)
_, err = tx.CopyFrom(ctx, pgx.Identifier{"temp_sync_data"}, columns, pgx.CopyFromRows(rows))
```

**Por que COPY FROM?**
- **~5-10x mais r√°pido** que INSERT em batch
- **Stream de dados**: N√£o carrega tudo na RAM do cliente
- **Integra√ß√£o nativa** com transa√ß√µes PostgreSQL

#### **CTE √önica para Processamento At√¥mico**
Ap√≥s o COPY FROM, executamos uma √∫nica **mega-query CTE** que faz todo o trabalho:

1. **Upsert Entities**: Insere/atualiza entidades com smart updates
2. **Collect References**: Coleta todas as refer√™ncias (entities + relationships)
3. **Map Entity IDs**: Resolve refer√™ncias de neg√≥cio ‚Üí IDs internos
4. **Upsert Relationships**: Cria/atualiza relacionamentos
5. **Return Affected IDs**: Retorna IDs das entidades que tiveram mudan√ßa real

Esta CTE utiliza `ON CONFLICT DO UPDATE WHERE IS DISTINCT FROM` para garantir que **apenas mudan√ßas reais** resultem em I/O de disco.

#### **Smart Cache Invalidation**
Com os IDs retornados pela CTE, solicitamos a invalida√ß√£o seletiva do cache Redis:

```go
// Invalida apenas entidades que tiveram mudan√ßa real
go func() {
    r.cachedGraphRepository.InvalidateByEntityIDs(ctx, affectedIDs)
}()
```

Isso permite que dados sejam **cacheados por muito tempo** (TTL alto), evitando leituras de disco nas opera√ß√µes de consulta.

### **2. Benef√≠cios da Estrat√©gia**

#### **COPY FROM vs INSERT em Batch**

| Vantagem | COPY FROM | INSERT em Batch |
|----------|-----------|-----------------|
| **Performance** | ~5-10x mais r√°pido | Baseline (100%) |
| **Memory usage** | Stream (constante) | Carrega batch inteiro na RAM |
| **Tuple size limit** | Sem limita√ß√£o | Limitado pelo tamanho da tupla |
| **Multi-table support** | Via tabela tempor√°ria | Restrito a 1 tabela por opera√ß√£o |
| **Error handling** | Falha total ou sucesso | Pode falhar parcialmente |
| **Protocol efficiency** | Protocolo bin√°rio otimizado | SQL parsing + planning overhead |

#### **CTE √önica vs M√∫ltiplas Queries**

| Aspecto | M√∫ltiplas Queries | CTE √önica |
|---------|-------------------|-----------|
| **Round-trips de rede** | 5-10 queries separadas | 1 √∫nica query |
| **Consistency** | Race conditions poss√≠veis | Atomicidade garantida |
| **Error handling** | Falha parcial complexa | Falha total ou sucesso |
| **Transaction overhead** | Alto (m√∫ltiplas opera√ß√µes) | Baixo (opera√ß√£o √∫nica) |

#### **I/O Optimization (Smart Updates)**

Utilizamos o padr√£o `WHERE IS DISTINCT FROM` que faz com que o PostgreSQL **n√£o execute I/O de disco** quando n√£o h√° mudan√ßa real:

```sql
ON CONFLICT (reference, type) DO UPDATE SET
  properties = excluded.properties,
  updated_at = NOW()
WHERE entities.properties IS DISTINCT FROM excluded.properties
```

#### **Cen√°rios de Otimiza√ß√£o de I/O**

| Cen√°rio | Exemplo | Resultado |
|---------|---------|-----------|
| **Batch totalmente duplicado** | 1000 msgs, 0 mudan√ßas reais | **0 disk writes** |
| **Partial changes** | 1000 msgs, 50 mudan√ßas reais | **50 disk writes** |
| **New entities only** | 1000 msgs, 1000 entities novas | **1000 inserts** |
| **Property merge identical** | Merge `{a:1}` + `{a:1}` | **0 disk writes** |
| **Property merge different** | Merge `{a:1}` + `{a:2}` | **1 disk write** |

#### **Cache Strategy Benefits**

| Vantagem | Implementa√ß√£o | Resultado |
|----------|---------------|-----------|
| **Selective invalidation** | Apenas IDs realmente afetados | Cache hit rate mantido |
| **Background processing** | Invalida√ß√£o ass√≠ncrona | Lat√™ncia baixa para writes |
| **High TTL viability** | Smart updates + invalidation | Menor carga no banco |

### **3. Reposit√≥rios**

#### **Graph Repository (Entities + Edges)**

O reposit√≥rio de grafo processa entidades e relacionamentos em uma √∫nica opera√ß√£o:

**Passo 1: Criar tabela tempor√°ria e COPY FROM**
```sql
-- Tabela tempor√°ria para staging
CREATE TEMP TABLE temp_sync_data (
    entity_type TEXT, entity_reference TEXT, entity_properties JSONB,
    source_reference TEXT, target_reference TEXT, relationship_type TEXT
) ON COMMIT DROP;

-- COPY FROM via pgx (stream de dados)
```

**Passo 2: CTE unificada para upsert at√¥mico**
```sql
WITH
-- CTE 1: Upsert entities com smart update
entities_upsert AS (
    INSERT INTO entities (type, reference, properties)
    SELECT DISTINCT entity_type, entity_reference, entity_properties
    FROM temp_sync_data
    WHERE entity_reference IS NOT NULL
    ON CONFLICT (type, reference) DO UPDATE SET
        properties = COALESCE(entities.properties, '{}'::jsonb) || excluded.properties,
        updated_at = NOW()
    WHERE COALESCE(entities.properties, '{}'::jsonb) || excluded.properties
          IS DISTINCT FROM entities.properties
    RETURNING id, reference, type
),

-- CTE 2: Coletar todas as refer√™ncias necess√°rias
all_references AS (
    SELECT DISTINCT entity_reference as reference, entity_type as type FROM temp_sync_data WHERE entity_reference IS NOT NULL
    UNION
    SELECT DISTINCT source_reference as reference, 'user' as type FROM temp_sync_data WHERE source_reference IS NOT NULL
    UNION
    SELECT DISTINCT target_reference as reference, 'unknown' as type FROM temp_sync_data WHERE target_reference IS NOT NULL
),

-- CTE 3: Mapear references ‚Üí IDs internos
entity_mapping AS (
    SELECT e.id, e.reference, e.type
    FROM entities e
    INNER JOIN all_references ar ON e.reference = ar.reference AND e.type = ar.type
    UNION ALL
    SELECT eu.id, eu.reference, eu.type FROM entities_upsert eu
),

-- CTE 4: Upsert relationships
edges_upsert AS (
    INSERT INTO edges (left_entity_id, right_entity_id, relationship_type)
    SELECT DISTINCT
        source_map.id,
        target_map.id,
        temp.relationship_type
    FROM temp_sync_data temp
    INNER JOIN entity_mapping source_map ON source_map.reference = temp.source_reference
    INNER JOIN entity_mapping target_map ON target_map.reference = temp.target_reference
    WHERE temp.relationship_type IS NOT NULL
    ON CONFLICT (left_entity_id, right_entity_id, relationship_type) DO UPDATE SET
        updated_at = NOW()
    WHERE edges.updated_at IS DISTINCT FROM excluded.updated_at
    RETURNING left_entity_id as entity_id
)

-- Retorna IDs afetados para cache invalidation
SELECT DISTINCT id as affected_entity_id FROM entities_upsert
UNION
SELECT DISTINCT entity_id as affected_entity_id FROM edges_upsert;
```

#### **Temporal Data Repository**

O reposit√≥rio de dados temporais foca em m√©tricas e time-series:

**Passo 1: Criar tabela tempor√°ria espec√≠fica**
```sql
CREATE TEMP TABLE temp_temporal_data (
    entity_reference TEXT, entity_type TEXT,
    property_key TEXT, property_value JSONB,
    granularity TEXT, reference_date TIMESTAMP,
    idempotency_key TEXT
) ON COMMIT DROP;
```

**Passo 2: CTE para temporal upsert**
```sql
WITH
-- CTE 1: Resolver entity references ‚Üí IDs
entity_resolution AS (
    SELECT DISTINCT
        e.id as entity_id,
        ttd.property_key,
        ttd.property_value,
        ttd.granularity,
        ttd.reference_date,
        ttd.idempotency_key
    FROM temp_temporal_data ttd
    INNER JOIN entities e ON e.reference = ttd.entity_reference AND e.type = ttd.entity_type
),

-- CTE 2: Upsert temporal properties com deduplica√ß√£o
temporal_upsert AS (
    INSERT INTO temporal_properties (entity_id, key, value, granularity, reference_date, idempotency_key)
    SELECT DISTINCT ON (entity_id, key, granularity, reference_date)
        entity_id, property_key, property_value, granularity, reference_date, idempotency_key
    FROM entity_resolution
    ORDER BY entity_id, key, granularity, reference_date, reference_date DESC -- newest wins em caso de conflito
    ON CONFLICT (idempotency_key) DO UPDATE SET
        value = excluded.value,
        updated_at = NOW()
    WHERE temporal_properties.value IS DISTINCT FROM excluded.value
    RETURNING entity_id
)

-- Retorna entity IDs afetados para cache invalidation
SELECT DISTINCT entity_id as affected_entity_id FROM temporal_upsert;
```

#### **Caracter√≠sticas dos Reposit√≥rios**

| Reposit√≥rio | Complexidade | Opera√ß√µes | Cache Invalidation |
|-------------|--------------|-----------|-------------------|
| **Graph Repository** | Alta (4 CTEs) | Entities + Edges | Por entity IDs afetados |
| **Temporal Repository** | M√©dia (2 CTEs) | Temporal properties apenas | Por entity IDs afetados |
| **Transaction Scope** | Single transaction | Atomic all-or-nothing | Background async |

## üìñ Read Repositories

### **1. Estrat√©gia de Leitura**

A estrat√©gia de leitura √© baseada em um **padr√£o Cache-Aside** otimizado que maximiza o cache hit rate e minimiza a lat√™ncia de consultas:

#### **Cache-First Strategy**
```go
// 1. Buscar no cache primeiro
cachedResult := r.redis.Get(ctx, cacheKey)
if cachedResult != nil {
    return cachedResult, nil
}

// 2. Cache miss: buscar no repositorio de leitura que usa a read replica do postgres
graphNodes, temporalProps, err := r.graphQueryRepository.QueryTree(ctx, condition, depthLimit, referenceMonth)
if err != nil {
  return nil, nil, fmt.Errorf("postgres query failed: %w", err)
}

// 3. Armazenar no cache para pr√≥ximas consultas
err = r.redisClient.SetWithRegistry(ctx, cacheKey, string(dataJSON), registryKeys)
if err != nil {
  log.Printf("Failed to set cache with registry for key %s: %v", cacheKey, err)
  return
}
```

Esta abordagem garante:
- **Lat√™ncia sub-milissegundo** para cache hits
- **Fallback autom√°tico** para read replicas PostgreSQL
- **Populate autom√°tico** do cache ap√≥s cache miss

#### **Smart Cache Key Strategy**
Utilizamos uma estrat√©gia sofisticada de chaves de cache que permite invalida√ß√£o seletiva:

```go
// Estrutura da chave de cache
cacheKey := fmt.Sprintf("graph:query:%s:depth:%d:entities:%s",
    hashQuery(condition), depthLimit, sortedEntityIDs)

// Exemplo real
cacheKey = "graph:query:a8f5f167:depth:3:entities:123,456,789"
```

**Componentes da chave:**
- **query hash**: Hash da condi√ß√£o de busca (WHERE clause)
- **depth limit**: Profundidade m√°xima do grafo
- **sorted entity IDs**: IDs das entidades envolvidas na consulta (ordenados)

#### **Query-Entity Association Mapping**
Para cada consulta cacheada, mantemos um **mapeamento reverso** que associa entidades √†s queries que as cont√©m:

```go
// Para cada query cacheada, registramos as entidades envolvidas
entityQueryMappings := map[string][]string{
    "entity:123": []string{"graph:query:a8f5f167:...", "graph:query:b9c2d891:..."},
    "entity:456": []string{"graph:query:a8f5f167:...", "graph:query:c3e4f012:..."},
    "entity:789": []string{"graph:query:d5f6g234:...", "graph:query:a8f5f167:..."},
}
```

**Benef√≠cios do mapping:**
- **Invalida√ß√£o seletiva**: Quando entity:123 muda, invalidamos apenas queries que a cont√©m
- **Cascade invalidation**: Uma mudan√ßa pode invalidar m√∫ltiplas queries relacionadas
- **Precision**: Evita invalida√ß√£o desnecess√°ria de queries n√£o relacionadas

### **2. Redis Pipeline Optimization**

#### **Batch Operations com Pipeline**
Utilizamos Redis Pipeline para realizar m√∫ltiplas opera√ß√µes em uma √∫nica round-trip de rede:

```go
// Pipeline para consulta + mapping em uma opera√ß√£o at√¥mica
pipe := r.redis.Pipeline()

// 1. Buscar resultado principal
resultCmd := pipe.Get(ctx, cacheKey)

// 2. Buscar metadados relacionados
metadataCmd := pipe.HGetAll(ctx, fmt.Sprintf("meta:%s", cacheKey))

// 3. Executar pipeline (1 round-trip)
_, err := pipe.Exec(ctx)

// 4. Processar resultados
result := resultCmd.Val()
metadata := metadataCmd.Val()
```

#### **Cache Population Pipeline**
Quando fazemos cache de uma nova consulta, usamos pipeline para opera√ß√µes at√¥micas:

```go
// Pipeline para cache + entity mapping
pipe := r.redis.Pipeline()

// 1. Armazenar resultado principal
pipe.Set(ctx, cacheKey, queryResult, TTL)

// 2. Registrar mapping reverso para cada entidade
for _, entityID := range involvedEntities {
    entityMappingKey := fmt.Sprintf("entity_queries:%d", entityID)
    pipe.SAdd(ctx, entityMappingKey, cacheKey)
    pipe.Expire(ctx, entityMappingKey, TTL)
}

// 3. Armazenar metadados da query
pipe.HSet(ctx, fmt.Sprintf("meta:%s", cacheKey), map[string]interface{}{
    "created_at": time.Now(),
    "entity_count": len(involvedEntities),
    "query_type": "graph_traversal",
})

// 4. Executar tudo atomicamente
_, err := pipe.Exec(ctx)
```

### **3. Cache Invalidation Strategy**

#### **Selective Invalidation Process**
Quando uma entidade √© atualizada (via Write Repository), executamos invalida√ß√£o seletiva:

```go
// 1. Buscar todas as queries que envolvem as entidades afetadas
func (r *CachedGraphRepository) InvalidateByEntityIDs(ctx context.Context, entityIDs []int64) error {
    pipe := r.redis.Pipeline()

    var queriesToInvalidate []string

    // 2. Para cada entidade afetada, buscar queries relacionadas
    for _, entityID := range entityIDs {
        entityMappingKey := fmt.Sprintf("entity_queries:%d", entityID)
        queries := r.redis.SMembers(ctx, entityMappingKey).Val()
        queriesToInvalidate = append(queriesToInvalidate, queries...)
    }

    // 3. Remover duplicatas
    uniqueQueries := removeDuplicates(queriesToInvalidate)

    // 4. Invalidar todas as queries afetadas em pipeline
    for _, queryKey := range uniqueQueries {
        pipe.Del(ctx, queryKey)
        pipe.Del(ctx, fmt.Sprintf("meta:%s", queryKey))
    }

    // 5. Limpar mappings das entidades afetadas
    for _, entityID := range entityIDs {
        entityMappingKey := fmt.Sprintf("entity_queries:%d", entityID)
        pipe.Del(ctx, entityMappingKey)
    }

    // 6. Executar invalida√ß√£o at√¥mica
    _, err := pipe.Exec(ctx)
    return err
}
```

#### **Background Invalidation**
A invalida√ß√£o acontece de forma **ass√≠ncrona** para n√£o bloquear writes:

```go
// No Write Repository, ap√≥s commit bem-sucedido
go func() {
    if err := r.cachedGraphRepository.InvalidateByEntityIDs(ctx, affectedEntityIDs); err != nil {
        logger.Error("Cache invalidation failed", "error", err, "entity_ids", affectedEntityIDs)
        // N√£o falha a opera√ß√£o de write por causa do cache
    }
}()
```

### **4. Benef√≠cios da Estrat√©gia de Leitura**

| Aspecto | Benef√≠cio | Implementa√ß√£o |
|---------|-----------|---------------|
| **High TTL Viability** | Cache por horas, n√£o minutos | Smart invalidation permite TTL alto |
| **Selective Invalidation** | Invalida apenas queries afetadas | Entity-query mapping reverso |
| **Pipeline Efficiency** | Reduz lat√™ncia de rede | Batch operations no Redis |
| **Graceful Degradation** | Funciona mesmo com cache down | Fallback autom√°tico para PostgreSQL |
| **Scalability** | Reduz carga no banco | Alto cache hit rate |


## ‚öôÔ∏è Workers

> **Todos os workers utilizam reposit√≥rios que implementam opera√ß√µes upsert** (INSERT + UPDATE) e s√£o otimizados para **evitar I/O desnecess√°rio** quando um batch n√£o cont√©m mudan√ßas reais.

### **1. Entities-Edges Consumer**

**üéØ Objetivo:** Popular dados de entidades e relacionamentos vindos de m√∫ltiplas origens processadas pelo Flink.

```bash
# Consome: entities-edges topic
# Processa: Entidades e seus relacionamentos em batches
# Persiste: via SyncGraph (entidades + relacionamentos)
```

**Payload Example (por mensagem):**
```json
{
  "id": "msg-uuid-123",
  "reference": "user-12345",
  "type": "user",
  "edges": [
    {
      "entity_reference": "company-abc",
      "entity_type": "company",
      "relation_type": "works_at"
    },
    {
      "entity_reference": "subscription-premium",
      "entity_type": "subscription",
      "relation_type": "has_subscription"
    }
  ]
}
```

**L√≥gica de Processamento:**
- **Batch aggregation**: Deduplica entidades por `reference`, mantendo vers√£o mais atual
- **Entity expansion**: Inclui automaticamente entidades referenciadas em relacionamentos
- **Upsert operation**: Chama `SyncGraph` para persistir via upsert otimizado

### **2. Entity-Properties Consumer**

**üéØ Objetivo:** Popular dados de propriedades de entidades vindos de v√°rias origens, com resolu√ß√£o autom√°tica de conflitos.

```bash
# Consome: entity-properties topic
# Processa: Propriedades individuais com conflict resolution
# Persiste: via SyncGraph (merge properties por timestamp)
```

**Payload Example (por mensagem):**
```json
{
  "entity_reference": "user-12345",
  "entity_type": "user",
  "field_name": "last_login",
  "field_value": "2025-01-15T10:30:00Z",
  "reference_date": "2025-01-15T10:30:00Z"
}
```

**L√≥gica de Processamento:**
- **Batch aggregation**: Agrupa por `entity_reference|entity_type`
- **Conflict resolution**: Resolve conflitos por `reference_date` (newer wins)
- **Property merging**: Combina m√∫ltiplos campos em um JSON properties final
- **Upsert operation**: Chama `SyncGraph` com entidades consolidadas

### **3. Temporal-Data Consumer**

**üéØ Objetivo:** Popular dados temporais (m√©tricas, KPIs, time-series) vindos de v√°rias origens anal√≠ticas e sistemas de neg√≥cio.

```bash
# Consome: temporal-data topic
# Processa: Dados temporais com deduplica√ß√£o por chave composta
# Persiste: via UpsertDataPoints (direto na tabela temporal_properties)
```

**Payload Example (por mensagem):**
```json
{
  "entity_reference": "user-12345",
  "entity_type": "user",
  "property_type": "transaction_metrics",
  "property_value": {
    "total_amount": 15420.50,
    "transaction_count": 23,
    "avg_ticket": 670.45
  },
  "property_reference_date": "2025-01-15T23:59:59Z",
  "property_granularity": "daily"
}
```

**L√≥gica de Processamento:**
- **Deduplication**: Deduplica por `entity|type|property_type|granularity|reference_date`
- **Conflict resolution**: Resolve por `property_reference_date` (newer wins)
- **JSON conversion**: Converte `property_value` para JSONB
- **Direct upsert**: Chama `UpsertDataPoints` com os dados temporais

### **4. CDC Consumer**

**üéØ Objetivo:** Converter eventos de escritas CDC em eventos de dom√≠nio padronizados para consumo downstream, garantindo integra√ß√£o confi√°vel.

```bash
# Consome: CDC events via Debezium
# Transforma: CDC events em Domain Events padronizados
# Publica: user-profile.domain-events.v1 topic (batch publishing)
```

#### **Padr√£o Outbox & Confiabilidade**

Utilizamos o **padr√£o Outbox** implementado via CDC para evitar o problema do **dual write**:

- **Zero Dual Write**: N√£o escrevemos diretamente em Kafka + banco simultaneamente
- **Single Source of Truth**: PostgreSQL √© a √∫nica fonte de verdade
- **Atomic Consistency**: CDC captura mudan√ßas ap√≥s commit bem-sucedido
- **Guaranteed Delivery**: Debezium garante entrega dos eventos (at-least-once)
- **Failure Recovery**: Em caso de falha, eventos s√£o reprocessados automaticamente

Esta abordagem √© **altamente confi√°vel** pois:
1. **N√£o perde eventos**: CDC captura 100% das mudan√ßas commitadas
2. **N√£o duplica dados**: Idempot√™ncia baseada em LSN (Log Sequence Number)
3. **Tolera falhas**: Restart autom√°tico do connector sem perda de dados

#### **Domain Event Structure**

Nossos eventos de dom√≠nio seguem uma estrutura padronizada:

**Event Body:**
```json
{
  "event_idempotency_key": "string",     // Hash MD5 para deduplica√ß√£o
  "event_timestamp": "2025-01-15T10:30:00Z",
  "data": {
    "type": "user",                      // Tipo da entidade (para entities)
    "reference": "user-12345",           // Business key da entidade
    "properties": {                      // Propriedades com old/new values
      "name": {
        "old": "Jo√£o",
        "new": "Jo√£o Silva"
      }
    }
  }
}
```

**Event Headers:**
```yaml
schema_version: v1                       # Vers√£o do schema
source_service: user-profile-api         # Servi√ßo origem
event_type: entity_properties_updated    # Tipo do evento para filtragem
event_id: uuid                          # ID √∫nico do evento
entity_type: user                        # Tipo da entidade (para entities)
fields_changed: name,email               # Campos alterados (CSV)
```

#### **CDC ‚Üí Domain Event Transformation**

**Como o dado chega do Debezium:**
```json
{
  "before": {
    "id": 123,
    "type": "user",
    "reference": "user-12345",
    "properties": "{\"name\":\"Jo√£o\",\"email\":\"joao@email.com\"}"
  },
  "after": {
    "id": 123,
    "type": "user",
    "reference": "user-12345",
    "properties": "{\"name\":\"Jo√£o Silva\",\"email\":\"joao@email.com\"}"
  },
  "source": {
    "table": "entities",
    "lsn": 184467440737095516,
    "ts_ms": 1705312200000
  },
  "op": "u"
}
```

**Como √© convertido para Domain Event:**
```json
{
  "event_idempotency_key": "9fb7bc7847854343384b8946668aba35",
  "event_timestamp": "2025-01-15T10:30:00Z",
  "data": {
    "type": "user",
    "reference": "user-12345",
    "properties": {
      "name": {
        "old": "Jo√£o",
        "new": "Jo√£o Silva"
      }
    }
  }
}
```

#### **Exemplos de Transforma√ß√£o por Cen√°rio**

**1. Entity Criada:**
```json
// Domain Event Body
{
    "event_idempotency_key": "241360e7712d5f36ea3cb35453fecee5",
    "event_timestamp": "2025-09-22T22:06:47.845Z",
    "data": {
        "type": "user",
        "reference": "user_aqNSvRZ_74",
        "properties": {
            "department": {
                "old": null,
                "new": {
                    "reference_date": "2025-09-22T23:34:59Z",
                    "value": "Finance"
                }
            },
            "name": {
                "old": null,
                "new": {
                    "reference_date": "2025-09-22T22:24:43Z",
                    "value": "Lady Leda Schulist"
                }
            },
            "position": {
                "old": null,
                "new": {
                    "reference_date": "2025-09-22T23:12:49Z",
                    "value": "Manager"
                }
            }
        }
    }
}

// Event Headers
{
    "schema_version": "v1",
    "source_service": "user-profile-api",
    "event_type": "entity_created",
    "event_id": "08c161b8-32a3-4e91-a510-5f47180293ad",
    "entity_type": "user",
    "fields_changed": "name,position,department"
}
```

**2. Entity Atualizada (apenas campos que mudaram):**
```json
// Domain Event Body
{
    "event_idempotency_key": "9fb7bc7847854343384b8946668aba35",
    "event_timestamp": "2025-09-23T11:42:56.973Z",
    "data": {
        "type": "user",
        "reference": "user-1d98ac68-00fa-4439-b5ec-43bfb0f3e4b8",
        "properties": {
            "email": {
                "old": {
                    "value": "batataa@example.com",
                    "verified_at": "2025-05-23T20:32:27.628939Z"
                },
                "new": {
                    "value": "batataa@examaple.com",
                    "verified_at": "2025-05-23T20:32:27.628939Z"
                }
            }
        }
    }
}

// Event Headers
{
    "schema_version": "v1",
    "source_service": "user-profile-api",
    "event_type": "entity_properties_updated",
    "event_id": "4341d2f2-cfae-4a26-90ad-febe51412c3c",
    "entity_type": "user",
    "fields_changed": "email"
}
```

**3. Relationship Criada:**
```json
// Domain Event Body
{
    "event_idempotency_key": "da7dde362579b0166bbd65e7c294e9c5",
    "event_timestamp": "2025-09-23T11:44:54.456Z",
    "data": {
        "reference": "entity-244731",
        "target_entity_reference": "entity-13",
        "properties": {
            "relationship_type": {
                "old": null,
                "new": "member_of"
            }
        }
    }
}

// Event Headers
{
    "schema_version": "v1",
    "source_service": "user-profile-api",
    "event_type": "relationship_created",
    "event_id": "eb04842b-45dc-4ace-a20e-6d6f1070fd87",
    "fields_changed": "relationship_type",
    "relation_type": "member_of"
}
```

**4. Relationship Atualizada:**
```json
// Domain Event Body
{
    "event_idempotency_key": "e0f5d3b5d7d489b2a8930bb25a88420f",
    "event_timestamp": "2025-09-23T11:42:56.978Z",
    "data": {
        "reference": "entity-3",
        "target_entity_reference": "entity-8",
        "properties": {
            "relationship_type": {
                "old": "his",
                "new": "has"
            }
        }
    }
}

// Event Headers
{
    "schema_version": "v1",
    "source_service": "user-profile-api",
    "event_id": "db157dfc-2fd9-4851-9608-ec03305d3497",
    "event_type": "relationship_updated",
    "fields_changed": "relationship_type",
    "relation_type": "has"
}
```

**5. Temporal Data Criada:**
```json
// Domain Event Body
{
    "event_idempotency_key": "69f1c7e6c5e30973956743bca4e3c39a",
    "event_timestamp": "2025-09-23T11:45:43.055Z",
    "data": {
        "reference": "entity-244732",
        "properties": {
            "granularity": {
                "old": null,
                "new": "month"
            },
            "idempotency_key": {
                "old": null,
                "new": "244732:tpv:month:2025-10"
            },
            "key": {
                "old": null,
                "new": "tpv"
            },
            "reference_date": {
                "old": null,
                "new": "2025-10-05T14:59:59Z"
            },
            "value": {
                "old": null,
                "new": "{\"items\": [{\"mdr\": 2, \"rav\": 999, \"amount\": 915103, \"chargeback\": 552, \"interchange\": 0, \"average_ticket\": 585, \"payment_method\": \"pix\", \"transaction_count\": 1564}]}"
            }
        }
    }
}

// Event Headers
{
    "schema_version": "v1",
    "source_service": "user-profile-api",
    "event_type": "temporal_data_created",
    "event_id": "89aa0356-eb84-4b19-820f-5e5626218793",
    "granularity": "month",
    "fields_changed": "items,key,granularity,reference_date,idempotency_key",
    "property_type": "tpv"
}
```

**6. Temporal Data Atualizada:**
```json
// Domain Event Body
{
    "event_idempotency_key": "69f1c7e6c5e30973956743bca4e3c39a",
    "event_timestamp": "2025-09-23T11:46:23.056Z",
    "data": {
        "reference": "entity-244732",
        "properties": {
            "value": {
                "old": "{\"items\": [{\"mdr\": 2, \"rav\": 999, \"amount\": 915103, \"chargeback\": 552, \"interchange\": 0, \"average_ticket\": 585, \"payment_method\": \"pix\", \"transaction_count\": 1564}]}",
                "new": "{\"items\": [{\"mdr\": 2, \"rav\": 1, \"amount\": 915103, \"chargeback\": 552, \"interchange\": 0, \"average_ticket\": 585, \"payment_method\": \"pix\", \"transaction_count\": 1564}]}"
            }
        }
    }
}

// Event Headers
{
    "schema_version": "v1",
    "source_service": "user-profile-api",
    "event_type": "temporal_data_updated",
    "event_id": "0028489d-7208-45a5-90be-751182fa86d8",
    "granularity": "month",
    "fields_changed": "value",
    "property_type": "tpv"
}
```

#### **L√≥gica de Processamento**

- **Batch transformation**: Processa m√∫ltiplos CDC events simultaneamente
- **Smart change detection**: Inclui apenas campos que realmente mudaram
- **Entity reference resolution**: Resolve IDs internos para business keys
- **Event enrichment**: Adiciona metadados e headers para filtragem downstream
- **Batch publishing**: Publica todos os domain events em um √∫nico batch
- **Idempotency**: Usa LSN do PostgreSQL para garantir processamento √∫nico
- **Error resilience**: Falhas individuais n√£o param o processamento do batch


## üåê API Endpoints

### **Graph Operations**

#### **GET /v1/graph/{id}**
Busca entidade por ID com relacionamentos e dados temporais.

**Query Parameters:**
- `period` (opcional): Data a partir da qual capturar dados temporais (formato: `2025-01-01T00:00:00Z`)
- `depth` (opcional): Profundidade m√°xima da √°rvore de relacionamentos (padr√£o: `3`, m√°ximo: `10`)

```bash
# Busca b√°sica
curl http://localhost:8888/v1/graph/123

# Com filtro temporal (apenas dados temporais >= 2025-01-01)
curl "http://localhost:8888/v1/graph/123?period=2025-01-01T00:00:00Z"

# Com profundidade limitada (apenas 2 n√≠veis de relacionamentos)
curl "http://localhost:8888/v1/graph/123?depth=2"

# Combinando par√¢metros
curl "http://localhost:8888/v1/graph/123?period=2025-01-01T00:00:00Z&depth=5"
```

**Response:**
```json
{
  "id": 7,
  "type": "user",
  "reference": "user-1d98ac68-00fa-4439-b5ec-43bfb0f3e4b8",
  "properties": {
    "email": {
      "value": {
        "address": "joao@email.com",
        "verified_at": "2025-05-23T20:32:27.628939Z"
      },
      "reference_date": "2025-09-23T08:42:56.481138Z"
    },
    "full_name": {
      "value": "Jo√£o Silva",
      "reference_date": "2025-09-22T17:48:19.948595Z"
    },
    "document": {
      "value": {
        "type": "cpf",
        "number": "12345678901"
      },
      "reference_date": "2025-09-22T17:48:19.948595Z"
    },
    "kyc_status": {
      "value": {
        "approved": true,
        "verification_level": "basic",
        "last_updated": "2024-11-26T23:57:48.375504Z"
      },
      "reference_date": "2024-11-26T23:57:48.375504Z"
    }
  },
  "created_at": "2025-09-22T17:48:19.948595-03:00",
  "updated_at": "2025-09-23T08:42:56.481138-03:00",
  "edges": [
    {
      "type": "member_of",
      "entity": {
        "id": 13,
        "type": "organization",
        "reference": "acc-12d2c3354786bf56",
        "properties": {
          "trade_name": {
            "value": "Stone Pagamentos",
            "reference_date": "2025-09-22T17:48:19.948595Z"
          },
          "document": {
            "value": "16501555000157",
            "reference_date": "2025-09-22T17:48:19.948595Z"
          },
          "account_status": {
            "value": {
              "overall_status": "active",
              "kyc_requirements": {
                "status": "approved"
              }
            },
            "reference_date": "2025-09-22T17:48:19.948595Z"
          }
        },
        "created_at": "2025-09-22T17:48:19.948595-03:00",
        "updated_at": "2025-09-22T17:48:19.948595-03:00",
        "edges": [
          {
            "type": "has",
            "entity": {
              "id": 2,
              "type": "affiliation",
              "reference": "aff-610d5848-61ce-49aa-a353-ac97dd026f6d",
              "properties": {
                "status": {
                  "value": "active",
                  "reference_date": "2025-09-22T17:44:01.236477Z"
                },
                "payment_methods": {
                  "value": ["visa", "elo", "pix"],
                  "reference_date": "2025-09-22T17:44:01.236477Z"
                }
              },
              "temporal_data": {
                "tpv": [
                  {
                    "value": {
                      "items": [
                        {
                          "amount": 16690430,
                          "payment_method": "pix",
                          "transaction_count": 29128
                        }
                      ]
                    },
                    "granularity": "month",
                    "reference_date": "2025-08-31T21:00:00-03:00"
                  }
                ]
              },
              "edges": [...],
              "created_at": "2025-09-22T17:44:01.236477-03:00",
              "updated_at": "2025-09-22T17:44:01.236477-03:00"
            }
          }
        ],
        "temporal_data": null
      }
    }
  ],
  "temporal_data": null
}
```

#### **GET /v1/graph/by-property/{prop}/value/{value}**
Busca entidade por propriedade JSON.

**Query Parameters:**
- `period` (opcional): Data a partir da qual capturar dados temporais (formato: `2025-01-01T00:00:00Z`)
- `depth` (opcional): Profundidade m√°xima da √°rvore de relacionamentos (padr√£o: `3`, m√°ximo: `10`)

```bash
# Busca b√°sica por email
curl http://localhost:8888/v1/graph/by-property/email/value/joao@email.com

# Com filtro temporal
curl "http://localhost:8888/v1/graph/by-property/email/value/joao@email.com?period=2025-01-01T00:00:00Z"

# Com profundidade limitada
curl "http://localhost:8888/v1/graph/by-property/department/value/Finance?depth=2"

# Combinando par√¢metros
curl "http://localhost:8888/v1/graph/by-property/status/value/active?period=2025-01-01T00:00:00Z&depth=5"
```

#### **POST /v1/graph/sync**
Sincroniza entidades e relacionamentos (upsert).

```bash
curl -X POST http://localhost:8888/v1/graph/sync \
  -H "Content-Type: application/json" \
  -d '{
    "entities": [
      {
        "reference": "user-12345",
        "type": "user",
        "properties": {
          "name": "Jo√£o Silva Updated",
          "status": "premium"
        }
      }
    ],
    "relationships": [
      {
        "source_reference": "user-12345",
        "target_reference": "subscription-premium",
        "relationship_type": "has_subscription"
      }
    ]
  }'
```

**Response:**
```json
{
  "status": "sync request accepted for processing"
}
```

### **Temporal Data Operations**

#### **POST /v1/temporal/ingest**
Ingest√£o de dados temporais/m√©tricas.

```bash
curl -X POST http://localhost:8888/v1/temporal/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "data_points": [
      {
        "entity_reference": "user-12345",
        "entity_type": "user",
        "key": "payment_metrics",
        "granularity": "daily",
        "reference_date": "2025-01-15T23:59:59Z",
        "value": {
          "transactions": 5,
          "total_amount": 2450.00,
          "average_ticket": 490.00
        }
      }
    ]
  }'
```

## üöÄ Setup & Opera√ß√£o

### **Pr√©-requisitos**
- Docker 20.10+
- Docker Compose 2.0+
- Make (GNU Make)
- 8GB RAM dispon√≠vel
- 20GB espa√ßo em disco

### **Quick Start**

```bash
# 1. Clone o reposit√≥rio
git clone <repo-url>
cd userprofilepoc

# 2. Configure DNS local para Redis
sudo tee -a /etc/hosts << EOF
127.0.0.1 redis-node-1
127.0.0.1 redis-node-2
127.0.0.1 redis-node-3
EOF

# 3. Suba toda a infraestrutura
docker compose up
```

### **Comandos Make Dispon√≠veis**

```bash
# Aplica√ß√£o Principal
make run-server                          # Executa o servidor HTTP da API

# Workers/Consumers
make run-entities-edges-consumer         # Consumer para entidades e relacionamentos
make run-entity-properties-consumer      # Consumer para propriedades de entidades
make run-temporal-data-consumer          # Consumer para dados temporais
make run-cdc-transformer                 # Transformer de eventos CDC para domain events

# Geradores de Dados
make run-datagen-postgres                # Gera dados diretamente no PostgreSQL
make run-datagen-kafka-entities-edges    # Gera eventos de entidades/edges no Kafka
make run-datagen-entity-properties       # Gera eventos de propriedades no Kafka
make run-datagen-temporal-data           # Gera dados temporais no Kafka

```

**Observa√ß√£o:** Para gerenciar a infraestrutura (PostgreSQL, Redis, Kafka), use Docker Compose diretamente:

```bash
# Infraestrutura
docker compose up -d                     # Sobe toda a infraestrutura
docker compose down                      # Para todos os servi√ßos
docker compose down -v                   # Para todos os servi√ßos e remove todos os volumes
```

### **UI Clients & Local Resources**

Ap√≥s subir a infraestrutura com `docker compose up -d`, os seguintes recursos ficam dispon√≠veis:

#### **üåê Web UIs**
```bash
# Kafka UI - Interface para gerenciar t√≥picos, consumers e mensagens
http://localhost:8080

# RedisInsight - Interface gr√°fica para gerenciar Redis cluster
http://localhost:5540
# Para conectar com os nos use: redis://redis-node-1:7001,redis-node-2:7002,redis-node-3:7003

# User Profile API - API principal do projeto
http://localhost:8888/v1/graph/1
```

#### **üîå Database Connections**
```bash
# PostgreSQL Primary (Write)
Host: localhost:5432
User: poc_user
Password: poc_password
Database: user_profile_db

# PostgreSQL Replica 1 (Read)
Host: localhost:5433
User: poc_user
Password: poc_password
Database: user_profile_db

# PostgreSQL Replica 2 (Read)
Host: localhost:5434
User: poc_user
Password: poc_password
Database: user_profile_db
```

#### **üì® Message Brokers & CDC**
```bash
# Apache Kafka
Brokers: localhost:9092
# Use Kafka UI (localhost:8080) para visualizar t√≥picos

# Debezium Connect
REST API: http://localhost:8083
# Gerencia conectores CDC para PostgreSQL ‚Üí Kafka

# Redis Cluster
Nodes: localhost:7001, localhost:7002, localhost:7003
# Use RedisInsight (localhost:5540) para visualizar dados
```

## üìä Testes de Carga

### **Estrat√©gia de Teste com K6**

Utilizamos **K6** para realizar testes de carga que simulam cen√°rios reais de uso da API, com foco especial em validar a efic√°cia do **cache strategy** e identificar gargalos de performance.

#### **Design dos Testes**

O teste foi projetado para ter um **percentual alto de cache miss** intencionalmente, atrav√©s de:

- **Query parameter variations**: Varia√ß√£o de `depth` (1-5) e `period` (datas diferentes)
- **Entity distribution**: Distribui√ß√£o uniforme entre entidades dispon√≠veis
- **Realistic patterns**: Simula√ß√£o de consultas reais com diferentes profundidades de grafo

```javascript
// Exemplo: Gera cache miss intencional
const depth = Math.floor(Math.random() * 5) + 1;  // 1-5
const period = randomDate();  // Varia per√≠odo dos dados temporais
const entityId = entities[Math.floor(Math.random() * entities.length)];
```

### **Prepara√ß√£o para Teste**

#### **1. Popular a Base de Dados**
```bash
# Gerar dados no PostgreSQL (10k usu√°rios, 500 bulk size, 10 consumers, 12 meses)
make run-datagen-postgres

# OU usar geradores Kafka
make run-datagen-kafka-entities-edges
make run-datagen-entity-properties
make run-datagen-temporal-data
```

#### **2. Gerar CSV de Entidades**
Necess√°rio gerar um CSV com colunas `id,email,cpf` para alimentar o teste:

```sql
-- Conectar no PostgreSQL e exportar dados
COPY (
  SELECT
    id,
    properties->>'email'->>'value' as email,
    properties->>'document'->>'value'->>'number' as cpf
  FROM entities
  WHERE type = 'user'
  AND properties->>'email' IS NOT NULL
  LIMIT 10000
) TO '/tmp/entities.csv' WITH CSV HEADER;
```

#### **3. Prepara√ß√£o de Recursos**
‚ö†Ô∏è **CR√çTICO**: Libere o m√°ximo de recursos da m√°quina:

- **Feche aplica√ß√µes desnecess√°rias**
- **Monitore uso de CPU, RAM, SWAP e I/O**
- **Considere que v√°rios componentes competem pelos mesmos recursos:**
  - PostgreSQL (primary + 2 replicas)
  - Redis cluster (3 nodes)
  - Kafka + Zookeeper
  - API + Workers
  - K6 test runner

**Experi√™ncia real:** Com 12 n√∫cleos, obtive **100% de uso de CPU, RAM, SWAP e I/O**, criando gargalos que prejudicaram o teste.

### **Configura√ß√£o do Teste K6**

#### **Stages - Perfil de Carga Gradual**

O teste utiliza um **ramp-up gradual** para simular crescimento org√¢nico de carga. Os `target` valores s√£o **VUs (Virtual Users)** - unidades virtuais que fazem chamadas **uma atr√°s da outra** de forma cont√≠nua.

**Como VUs funcionam:**
- Cada VU executa requests **sequencialmente** (n√£o paralelo)
- **Quanto mais r√°pido** a API responder, **mais requests** o VU far√° no mesmo per√≠odo
- Cada chamada √© para uma **entidade diferente** com **depth e period √∫nicos**
- RPS final = `VUs √ó (1 / tempo_resposta_m√©dio)`

**Exemplo:** 1000 VUs com resposta m√©dia de 250ms = ~4000 RPS te√≥rico

```javascript
export let options = {
  stages: [
    // Ramp-up gradual
    { duration: '2m', target: 100 },   // 0-100 users em 2 min
    { duration: '3m', target: 500 },   // 100-500 users em 3 min
    { duration: '5m', target: 1000 },  // 500-1000 users em 5 min
    // { duration: '10m', target: 2000 }, // 1000-2000 users em 10 min (pico m√°ximo)
    { duration: '5m', target: 1000 },  // Manter em 1000 (plat√¥)
    { duration: '3m', target: 0 },     // Ramp-down gradual
  ],
  thresholds: {
    http_req_duration: ['p(90)<1000', 'p(95)<2000', 'p(99)<5000'], // P90 < 1s, P95 < 2s, P99 < 5s
    http_req_failed: ['rate<0.1'],     // Error rate < 10%
    errors: ['rate<0.05'],             // Error rate customizado < 5%
    cache_hits: ['rate>0.7'],          // Cache hit rate > 70%
  },
};
```

#### **Fases do Teste**

| Fase | Dura√ß√£o | VUs | RPS Esperado* | Objetivo |
|------|---------|-----|---------------|----------|
| **Warm-up** | 2min | 0‚Üí100 | 0‚Üí400 | Aquecimento do sistema, popula√ß√£o inicial do cache |
| **Load increase** | 3min | 100‚Üí500 | 400‚Üí2000 | Aumento gradual de carga, teste de escalabilidade |
| **Peak load** | 5min | 500‚Üí1000 | 2000‚Üí4000 | Carga m√°xima, identifica√ß√£o de limites |
| **Sustain** | 5min | 1000 | 2500-4000 | Teste de estabilidade sob carga constante |
| **Ramp-down** | 3min | 1000‚Üí0 | 4000‚Üí0 | Verifica√ß√£o de graceful degradation |

***RPS varia conforme performance da API** - quanto mais r√°pida, maior o RPS com mesmo n√∫mero de VUs

**Total:** 18 minutos de teste

#### **Thresholds - Crit√©rios de Sucesso**

| Threshold | Limite | Prop√≥sito |
|-----------|--------|-----------|
| **P90 < 1s** | `p(90)<1000` | 90% das requests devem ser < 1 segundo |
| **P95 < 2s** | `p(95)<2000` | 95% das requests devem ser < 2 segundos |
| **P99 < 5s** | `p(99)<5000` | 99% das requests devem ser < 5 segundos |
| **Error rate < 10%** | `rate<0.1` | Taxa de falha HTTP aceit√°vel |
| **Custom errors < 5%** | `rate<0.05` | Erros de aplica√ß√£o baixos |
| **Cache hit > 70%** | `rate>0.7` | Efic√°cia m√≠nima do cache |

### **Executando o Teste**

```bash
# 1. Certificar que a infraestrutura est√° rodando
docker compose ps

# 2. Verificar recursos dispon√≠veis
htop  # Monitorar CPU/RAM
iostat -x 1  # Monitorar I/O

# 3. Executar o teste K6 (carrega CSV em mem√≥ria)
k6 run load-test.js

# 4. Monitoramento em tempo real (opcional)
# Terminal 2: docker stats
# Terminal 3: redis-cli -p 7001 info stats
```

### **Interpretando os Resultados**

#### **Exemplo Real de Resultado**

```bash
INFO[1081] üèÅ Load test completed in 1080.8 seconds
INFO[1081] üìà Check the summary for detailed metrics
INFO[1081] üî• Expected: MUCH lower cache hits due to query parameter variations
INFO[1081] üí° Compare with previous test results to see cache impact

‚ñà THRESHOLDS
  cache_hits
  ‚úó 'rate>0.7' rate=65.21%         # Cache hit rate abaixo do threshold
  errors
  ‚úì 'rate<0.05' rate=0.00%        # Taxa de erro dentro do esperado
  http_req_duration
  ‚úì 'p(90)<1000' p(90)=922.76ms   # P90 latency aceit√°vel
  ‚úì 'p(95)<2000' p(95)=1.02s      # P95 latency dentro do limite
  ‚úì 'p(99)<5000' p(99)=1.31s      # P99 latency aceit√°vel
  http_req_failed
  ‚úì 'rate<0.1' rate=0.00%         # Falhas de requisi√ß√£o baixas

‚ñà TOTAL RESULTS
  checks_total.......: 8101113 7494.926407/s
  checks_succeeded...: 99.99%  8100923 out of 8101113

  CUSTOM METRICS
  cache_hits................: 65.21%  1761097 out of 2700371
  errors....................: 0.00%   108 out of 2700371
  response_time.............: avg=248.95ms med=18.32ms p(90)=922.76ms p(95)=1.02s

  HTTP METRICS
  http_req_duration.........: avg=248.95ms p(90)=922.76ms p(95)=1.02s p(99)=1.31s
  http_req_failed...........: 0.00%   82 out of 2700374
  http_reqs.................: 2700374 2498.311578/s  # ~2.5k RPS

  EXECUTION
  iterations................: 2700371 2498.308802/s
  vus.......................: 2       min=1 max=1000

  NETWORK
  data_received.............: 8.8 GB  8.1 MB/s
  data_sent.................: 439 MB  406 kB/s

running (18m00.9s), 0000/1000 VUs, 2700371 complete and 0 interrupted iterations
```

#### **An√°lise dos Resultados**

| M√©trica | Valor | Interpreta√ß√£o |
|---------|-------|---------------|
| **RPS** | 2,498 req/s | Throughput excelente considerando cache miss alto |
| **Cache Hit Rate** | 65.21% | Baixo devido √†s varia√ß√µes intencionais de par√¢metros |
| **P95 Latency** | 1.02s | Aceit√°vel para consultas complexas de grafo |
| **Error Rate** | 0.00% | Sistema manteve estabilidade sob carga |
| **Data Transfer** | 8.8 GB received | Volume significativo de dados processados |

#### **M√©tricas-Chave para Avaliar**

**‚úÖ Positivos:**
- **Zero error rate**: Sistema resiliente sob carga
- **Consistent performance**: P99 dentro de limites aceit√°veis
- **High throughput**: ~2.5k RPS com queries complexas
- **Cache effectiveness**: Mesmo com miss alto, performance mantida

**‚ö†Ô∏è Pontos de Aten√ß√£o:**
- **Resource contention**: 100% CPU/RAM/I/O indica gargalo de infraestrutura
- **Cache miss impact**: 65% cache hit vs target de 70%+ mostra room for improvement
- **Latency variance**: Gap entre median (18ms) e P95 (1.02s) indica variabilidade



---

*Este README √© um documento vivo. Mantenha-o atualizado conforme a evolu√ß√£o do projeto.*